import os
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime


class DataCollector:
    def __init__(self, logger, config):
        self.logger = logger
        self.data_sources = config.get("data_sources", [])

    def build_url(self, stock, start_date, end_date, source):
        if "finance.yahoo.com" in source:
            return f"https://finance.yahoo.com/quote/{stock}/history?p={stock}"
        elif "nasdaq.com" in source:
            return f"https://www.nasdaq.com/market-activity/stocks/{stock}/historical"
        elif "investing.com" in source:
            # Investing.com Ğ¼Ğ¾Ğ¶Ğµ Ğ²Ğ¸Ğ¼Ğ°Ğ³Ğ°Ñ‚Ğ¸ Ñ–Ğ½ÑˆĞ¸Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ–Ğ²
            return f"https://www.investing.com/equities/{stock}-historical-data"
        else:
            self.logger.warning(f"âš ï¸ ĞĞµĞ²Ñ–Ğ´Ğ¾Ğ¼Ğ¸Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ URL Ğ´Ğ»Ñ Ğ´Ğ¶ĞµÑ€ĞµĞ»Ğ°: {source}")
            return None

    def fetch_data(self, stock, start_date, end_date):
        url = self.build_url(stock, start_date, end_date)
        if not url:
            self.logger.error(f"âŒ ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ¿Ğ¾Ğ±ÑƒĞ´ÑƒĞ²Ğ°Ñ‚Ğ¸ URL Ğ´Ğ»Ñ {stock} Ğ· {start_date} Ğ´Ğ¾ {end_date}.")
            return pd.DataFrame()

        self.logger.info(f"ğŸ“¥ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ´Ğ»Ñ {stock} Ğ· {start_date} Ğ´Ğ¾ {end_date}...")
        try:
            response = requests.get(url)
            response.raise_for_status()

            # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ HTML Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– Ğ· Ğ´Ğ°Ğ½Ğ¸Ğ¼Ğ¸
            soup = BeautifulSoup(response.text, "html.parser")
            table = soup.find("table")
            if not table:
                self.logger.warning(f"âš ï¸ ĞĞµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†ÑŒ Ğ´Ğ»Ñ {stock} Ğ½Ğ° {url}.")
                return pd.DataFrame()

            headers = [th.get_text(strip=True) for th in table.find_all("th")]
            rows = [[td.get_text(strip=True) for td in row.find_all("td")] for row in table.find_all("tr")]

            # ĞŸĞµÑ€ĞµÑ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ğ½Ğ° DataFrame
            data = pd.DataFrame(rows, columns=headers)

            # Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€ÑƒÑ”Ğ¼Ğ¾ Ğ´Ğ°Ğ½Ñ– Ğ·Ğ° Ğ´Ğ°Ñ‚Ğ¾Ñ
            data["Date"] = pd.to_datetime(data["Date"], errors="coerce")
            data.dropna(subset=["Date"], inplace=True)
            data = data[(data["Date"] >= pd.to_datetime(start_date)) & (data["Date"] <= pd.to_datetime(end_date))]

            # Ğ¡ĞºĞ¸Ğ´Ğ°Ñ”Ğ¼Ğ¾ Ñ–Ğ½Ğ´ĞµĞºÑ Ñ– Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ”Ğ¼Ğ¾ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ñ– Ğ´Ğ°Ğ½Ñ–
            data.reset_index(drop=True, inplace=True)
            self.logger.info(f"âœ… Ğ”Ğ°Ğ½Ñ– ÑƒÑĞ¿Ñ–ÑˆĞ½Ğ¾ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ñ–: {data.shape[0]} Ñ€ÑĞ´ĞºÑ–Ğ², {data.shape[1]} ÑÑ‚Ğ¾Ğ²Ğ¿Ñ†Ñ–Ğ².")
            return data

        except Exception as e:
            self.logger.error(f"âŒ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ´Ğ»Ñ {stock}: {e}")
            return pd.DataFrame()
